{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import vgg16, densenet121, resnet152\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization parameters for pre-trained PyTorch models\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, dataset_path, split_path, split_number, input_shape, sequence_length, training):\n",
    "        super().__init__()\n",
    "        self.training = training\n",
    "        self.label_index = self._extract_label_mapping(split_path)\n",
    "        self.sequences = self._extract_sequence_paths(dataset_path, split_path, split_number, training)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.label_names = sorted(list(set([self._activity_from_path(seq_path) for seq_path in self.sequences])))\n",
    "        self.num_classes = len(self.label_names)\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(input_shape[-2:], Image.BICUBIC),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        )\n",
    "        with open('audio_features_remade.pickle', 'rb') as handle:\n",
    "            self.audio_features = pickle.load(handle)\n",
    "\n",
    "    def _extract_label_mapping(self, split_path=\"train_test_split\"):\n",
    "        \"\"\" Extracts a mapping between activity name and softmax index \"\"\"\n",
    "        with open(os.path.join(split_path, \"classInd.txt\")) as file:\n",
    "            lines = file.read().splitlines()\n",
    "        label_mapping = {}\n",
    "        for line in lines:\n",
    "            label, action = line.split()\n",
    "            label_mapping[action] = int(label) - 1\n",
    "        return label_mapping\n",
    "\n",
    "    def _extract_sequence_paths(\n",
    "        self, dataset_path, split_path=\"train_test_split\", split_number=1, training=True\n",
    "    ):\n",
    "        \"\"\" Extracts paths to sequences given the specified train / test split \"\"\"\n",
    "        assert split_number in [1, 2, 3], \"Split number has to be one of {1, 2, 3}\"\n",
    "        fn = f\"trainlist0{split_number}.txt\" if training else f\"testlist0{split_number}.txt\"\n",
    "        split_path = os.path.join(split_path, fn)\n",
    "        with open(split_path) as file:\n",
    "            lines = file.read().splitlines()\n",
    "        sequence_paths = []\n",
    "        for line in lines:\n",
    "            seq_name = line.split(\".avi\")[0]\n",
    "            sequence_paths += [os.path.join(dataset_path, seq_name)]\n",
    "        return sequence_paths\n",
    "\n",
    "    def _activity_from_path(self, path):\n",
    "        \"\"\" Extracts activity name from filepath \"\"\"\n",
    "        return path.split(\"/\")[-2]\n",
    "\n",
    "    def _frame_number(self, image_path):\n",
    "        \"\"\" Extracts frame number from filepath \"\"\"\n",
    "        return int(image_path.split(\"/\")[-1].split(\".jpg\")[0])\n",
    "\n",
    "    def _pad_to_length(self, sequence):\n",
    "        \"\"\" Pads the sequence to required sequence length \"\"\"\n",
    "        left_pad = sequence[0]\n",
    "        if self.sequence_length is not None:\n",
    "            while len(sequence) < self.sequence_length:\n",
    "                sequence.insert(0, left_pad)\n",
    "        return sequence\n",
    "    \n",
    "    def _get_audio_features(self, sequence):\n",
    "        \"\"\" Get the audio features from the pickle \"\"\"\n",
    "        # Hardcoded\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sequence_path = self.sequences[index % len(self)]\n",
    "        image_name =  sequence_path.split('/')[-1]+\".wav\"\n",
    "        # Extract audio features based on video name\n",
    "        audio = self.audio_features[image_name]\n",
    "        audio = torch.Tensor(audio)\n",
    "        # Sort frame sequence\n",
    "        image_paths = sorted(glob.glob(f\"{sequence_path}/*.jpg\"), key=lambda path: self._frame_number(path))\n",
    "        # If shorter than length, pad to length\n",
    "        image_paths = self._pad_to_length(image_paths)\n",
    "        if self.training:\n",
    "            # Randomly choose sample interval and start frame\n",
    "            sample_interval = np.random.randint(1, len(image_paths) // self.sequence_length + 1)\n",
    "            start_i = np.random.randint(0, len(image_paths) - sample_interval * self.sequence_length + 1)\n",
    "            flip = np.random.random() < 0.5\n",
    "        else:\n",
    "            # Start at first frame and sample uniformly over sequence\n",
    "            start_i = 0\n",
    "            sample_interval = 1 if self.sequence_length is None else len(image_paths) // self.sequence_length\n",
    "            flip = False\n",
    "        # Extract frames as tensors\n",
    "        image_sequence = []\n",
    "        for i in range(start_i, len(image_paths), sample_interval):\n",
    "            if self.sequence_length is None or len(image_sequence) < self.sequence_length:\n",
    "                image_tensor = self.transform(Image.open(image_paths[i]))\n",
    "                if flip:\n",
    "                    image_tensor = torch.flip(image_tensor, (-1,))\n",
    "                image_sequence.append(image_tensor)\n",
    "        image_sequence = torch.stack(image_sequence)\n",
    "        target = self.label_index[self._activity_from_path(sequence_path)]\n",
    "        \n",
    "        \n",
    "        return image_sequence, target, audio\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#         Encoder\n",
    "##############################\n",
    "\n",
    "# This encoder is currently using VGG16\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        model = vgg16(pretrained=True) \n",
    "        self.feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(25088, latent_dim), nn.BatchNorm1d(latent_dim, momentum=0.01)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.final(x)\n",
    "\n",
    "    \n",
    "##############################\n",
    "#           LSTM\n",
    "##############################\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, latent_dim, num_layers, hidden_dim, bidirectional):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(latent_dim, hidden_dim, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.hidden_state = None\n",
    "\n",
    "    def reset_hidden_state(self):\n",
    "        self.hidden_state = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, self.hidden_state = self.lstm(x, self.hidden_state)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "##############################\n",
    "#         ConvLSTM\n",
    "##############################\n",
    "\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_classes, latent_dim=512, lstm_layers=1, hidden_dim=1024, bidirectional=True, attention=True\n",
    "    ):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.lstm = LSTM(latent_dim, lstm_layers, hidden_dim, bidirectional)\n",
    "        self.output_layers = nn.Sequential(\n",
    "#             nn.Linear((2 * hidden_dim if bidirectional else hidden_dim), hidden_dim),\n",
    "            nn.Linear((2 * hidden_dim if bidirectional else hidden_dim)+609, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim, momentum=0.01),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "        self.attention = attention\n",
    "        self.attention_layer = nn.Linear(2 * hidden_dim if bidirectional else hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, audio):\n",
    "        batch_size, seq_length, c, h, w = x.shape\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(batch_size, seq_length, -1)\n",
    "        x = self.lstm(x)\n",
    "        if self.attention:\n",
    "            attention_w = F.softmax(self.attention_layer(x).squeeze(-1), dim=-1)\n",
    "            x = torch.sum(attention_w.unsqueeze(-1) * x, dim=1)\n",
    "        else:\n",
    "            x = x[:, -1]\n",
    "            \n",
    "        x = torch.cat((x, audio), dim=1)\n",
    "        return self.output_layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (3, 224, 224)\n",
    "\n",
    "dataset_path = \"UCF_49-frames\"\n",
    "split_path = \"train_test_split\"\n",
    "split_number = 1\n",
    "sequence_length = 50\n",
    "batch_size = 4\n",
    "latent_dim = 256\n",
    "num_epochs = 15\n",
    "checkpoint_model = \"\"\n",
    "checkpoint_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training set\n",
    "train_dataset = Dataset(\n",
    "    dataset_path=dataset_path,\n",
    "    split_path=split_path,\n",
    "    split_number=split_number,\n",
    "    input_shape=image_shape,\n",
    "    sequence_length=sequence_length,\n",
    "    training=True\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Define test set\n",
    "test_dataset = Dataset(\n",
    "    dataset_path=dataset_path,\n",
    "    split_path=split_path,\n",
    "    split_number=split_number,\n",
    "    input_shape=image_shape,\n",
    "    sequence_length=sequence_length,\n",
    "    training=False\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Classification criterion\n",
    "cls_criterion = nn.CrossEntropyLoss().to(device)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTM(\n",
      "  (encoder): Encoder(\n",
      "    (feature_extractor): Sequential(\n",
      "      (0): Sequential(\n",
      "        (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu0): ReLU(inplace=True)\n",
      "        (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (denseblock1): _DenseBlock(\n",
      "          (denselayer1): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer2): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer3): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer4): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer5): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer6): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (transition1): _Transition(\n",
      "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "        (denseblock2): _DenseBlock(\n",
      "          (denselayer1): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer2): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer3): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer4): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer5): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer6): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer7): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer8): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer9): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer10): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer11): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer12): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (transition2): _Transition(\n",
      "          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "        (denseblock3): _DenseBlock(\n",
      "          (denselayer1): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer2): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer3): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer4): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer5): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer6): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer7): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer8): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer9): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer10): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer11): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer12): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer13): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer14): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer15): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer16): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer17): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer18): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer19): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer20): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer21): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer22): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer23): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer24): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (transition3): _Transition(\n",
      "          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "        (denseblock4): _DenseBlock(\n",
      "          (denselayer1): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer2): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer3): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer4): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer5): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer6): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer7): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer8): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer9): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer10): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer11): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer12): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer13): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer14): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer15): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (denselayer16): _DenseLayer(\n",
      "            (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu1): ReLU(inplace=True)\n",
      "            (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu2): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (final): Sequential(\n",
      "      (0): Linear(in_features=50176, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (lstm): LSTM(\n",
      "    (lstm): LSTM(256, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (output_layers): Sequential(\n",
      "    (0): Linear(in_features=1633, out_features=512, bias=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=49, bias=True)\n",
      "    (4): Softmax(dim=-1)\n",
      "  )\n",
      "  (attention_layer): Linear(in_features=1024, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define network\n",
    "model = ConvLSTM(\n",
    "    num_classes=train_dataset.num_classes,\n",
    "    latent_dim=latent_dim,\n",
    "    lstm_layers=1,\n",
    "    hidden_dim=512,\n",
    "    bidirectional=True,\n",
    "    attention=True,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "        \n",
    "        \n",
    "# Add weights from checkpoint model if specified\n",
    "if checkpoint_model:\n",
    "    model.load_state_dict(torch.load(opt.checkpoint_model))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(epoch):\n",
    "    model.eval()\n",
    "    test_metrics = {\"loss\": [], \"acc\": []}\n",
    "    for images, labels, audio in tqdm(test_dataloader):\n",
    "        image_sequences = Variable(images.to(device), requires_grad=False)\n",
    "        audio_sequences = Variable(audio.to(device), requires_grad=False)\n",
    "        labels = Variable(labels, requires_grad=False).to(device)\n",
    "        with torch.no_grad():\n",
    "            # Reset LSTM hidden state\n",
    "            model.lstm.reset_hidden_state()\n",
    "            # Get sequence predictions\n",
    "            predictions = model(image_sequences, audio_sequences)\n",
    "        # Compute metrics\n",
    "        acc = 100 * (predictions.detach().argmax(1) == labels).cpu().numpy().mean()\n",
    "        loss = cls_criterion(predictions, labels).item()\n",
    "        # Keep track of loss and accuracy\n",
    "        test_metrics[\"loss\"].append(loss)\n",
    "        test_metrics[\"acc\"].append(acc)\n",
    "    model.train()\n",
    "    return test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1177 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 0 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [22:50<00:00,  1.16s/it]\n",
      "100%|██████████| 470/470 [06:44<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/15 -  Training Loss: 3.892 (3.890) Training Acc: 0.000 (3.717) Test Loss: 3.862 (3.887) Test Acc: 33.333 (5.390)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1177 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [22:23<00:00,  1.14s/it]\n",
      "100%|██████████| 470/470 [06:31<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15 -  Training Loss: 3.901 (3.884) Training Acc: 0.000 (4.418) Test Loss: 3.874 (3.881) Test Acc: 0.000 (5.213)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1177 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [22:21<00:00,  1.14s/it]\n",
      "100%|██████████| 470/470 [06:29<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/15 -  Training Loss: 3.903 (3.881) Training Acc: 0.000 (4.673) Test Loss: 3.872 (3.877) Test Acc: 0.000 (4.521)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1177 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [22:05<00:00,  1.13s/it]\n",
      "100%|██████████| 470/470 [06:28<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/15 -  Training Loss: 3.907 (3.878) Training Acc: 0.000 (4.928) Test Loss: 3.853 (3.876) Test Acc: 0.000 (5.372)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1177 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [19:20<00:00,  1.01it/s]\n",
      "100%|██████████| 470/470 [05:15<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15 -  Training Loss: 3.889 (3.874) Training Acc: 0.000 (5.607) Test Loss: 3.857 (3.876) Test Acc: 0.000 (5.957)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1177 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [19:17<00:00,  1.02it/s]\n",
      "100%|██████████| 470/470 [05:15<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/15 -  Training Loss: 3.891 (3.871) Training Acc: 0.000 (6.542) Test Loss: 3.863 (3.872) Test Acc: 0.000 (5.957)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1177 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [19:16<00:00,  1.02it/s]\n",
      "100%|██████████| 470/470 [05:15<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/15 -  Training Loss: 3.713 (3.867) Training Acc: 33.333 (7.016) Test Loss: 3.841 (3.874) Test Acc: 0.000 (5.957)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1177 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [19:01<00:00,  1.03it/s]\n",
      "100%|██████████| 470/470 [05:17<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/15 -  Training Loss: 3.910 (3.865) Training Acc: 0.000 (6.797) Test Loss: 3.792 (3.870) Test Acc: 0.000 (6.170)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1177 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 835/1177 [13:14<04:47,  1.19it/s]"
     ]
    }
   ],
   "source": [
    "logfile = 'log_densenet121_with_audio.txt'\n",
    "test_metrics = {}\n",
    "epoch_metrics = {}\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_metrics[epoch] = {\"loss\": [], \"acc\": []}\n",
    "    prev_time = time.time()\n",
    "    with open(logfile, 'a') as log: \n",
    "        log.write(f\"--- Epoch {epoch} ---\\n\")\n",
    "        log.close()\n",
    "    print(f\"--- Epoch {epoch} ---\")\n",
    "    for images, labels, audio in tqdm(train_dataloader):\n",
    "        if images.size(0) == 1:\n",
    "            continue\n",
    "\n",
    "        image_sequences = Variable(images.to(device), requires_grad=True)\n",
    "        audio_sequences = Variable(audio.to(device), requires_grad=True)\n",
    "        labels = Variable(labels.to(device), requires_grad=False)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Reset LSTM hidden state\n",
    "        model.lstm.reset_hidden_state()\n",
    "\n",
    "        # Get sequence predictions\n",
    "        predictions = model(image_sequences, audio_sequences)\n",
    "\n",
    "        # Compute metrics\n",
    "        loss = cls_criterion(predictions, labels)\n",
    "        acc = 100 * (predictions.detach().argmax(1) == labels).cpu().numpy().mean()\n",
    "        # Use this line to see in real time the predictions\n",
    "        # print(\"predictions: \", predictions.detach().argmax(1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Keep track of epoch metrics\n",
    "        epoch_metrics[epoch][\"loss\"].append(loss.item())\n",
    "        epoch_metrics[epoch][\"acc\"].append(acc)\n",
    "\n",
    "        # Empty cache\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_metrics[epoch] = test_model(epoch)\n",
    "    \n",
    "    with open(logfile, 'a') as log: \n",
    "        with open(logfile, 'a') as log: \n",
    "            log.write(\"Epoch: {}/{} - \".format(epoch, num_epochs))\n",
    "            log.write(\"Training Loss: {:.3f} ({:.3f}) \".format(epoch_metrics[epoch][\"loss\"][-1], np.mean(epoch_metrics[epoch][\"loss\"])))\n",
    "            log.write(\"Training Acc: {:.3f} ({:.3f}) \".format(epoch_metrics[epoch][\"acc\"][-1], np.mean(epoch_metrics[epoch][\"acc\"])))\n",
    "            log.write(\"Test Loss: {:.3f} ({:.3f}) \".format(test_metrics[epoch][\"loss\"][-1], np.mean(test_metrics[epoch][\"loss\"])))\n",
    "            log.write(\"Test Acc: {:.3f} ({:.3f})\\n\".format(test_metrics[epoch][\"acc\"][-1], np.mean(test_metrics[epoch][\"acc\"])))\n",
    "    \n",
    "    print(\"Epoch: {}/{} - \".format(epoch, num_epochs),\n",
    "          \"Training Loss: {:.3f} ({:.3f})\".format(epoch_metrics[epoch][\"loss\"][-1], np.mean(epoch_metrics[epoch][\"loss\"])),\n",
    "          \"Training Acc: {:.3f} ({:.3f})\".format(epoch_metrics[epoch][\"acc\"][-1], np.mean(epoch_metrics[epoch][\"acc\"])),\n",
    "          \"Test Loss: {:.3f} ({:.3f})\".format(test_metrics[epoch][\"loss\"][-1], np.mean(test_metrics[epoch][\"loss\"])),\n",
    "          \"Test Acc: {:.3f} ({:.3f})\".format(test_metrics[epoch][\"acc\"][-1], np.mean(test_metrics[epoch][\"acc\"])))\n",
    "\n",
    "    # Save model checkpoint\n",
    "    if epoch % checkpoint_interval == 0:\n",
    "        os.makedirs(\"model_checkpoints\", exist_ok=True)\n",
    "        torch.save(model.state_dict(), f\"model_checkpoints_with_audio/{model.__class__.__name__}_{epoch}.pth\")\n",
    "        \n",
    "# Save training and testing metrics for graphing (optional)        \n",
    "with open('train_metrics.pickle', 'wb') as handle:\n",
    "    pickle.dump(epoch_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('test_metrics.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
